import os
import concurrent.futures

import traceback
import numpy as np
import pandas as pd

import psutil
import sys
import time
import datetime
from datetime import timedelta
from dateutil import parser
import pytz
import threading
import concurrent.futures
import pyqtgraph as pg
from qtpy.QtCore import Qt
from qtpy import QtWidgets

sys.path.append(
    os.path.abspath(os.path.join(os.path.dirname(__file__), "../..", "neuroshare/pyns"))
)
sys.path.append(os.path.dirname(__file__))

from nsfile import NSFile
from nsentity import EntityType

from core.utils import get_elapsed_time, get_time_hrs_mins_secs_ms
from dsp.spike_detection import detect_spikes
from core.transcribe_audio import transcribe_audio

# import spikeinterface.sorters as ss

LINES_ONOFF = 13
BLANK_ON = 11
LINES_FLIP_BLANK = 103
LINES_FLIP_PIC = 22
TRIAL_ON = 26
DATA_SIGNATURE_ON = 64
DATA_SIGNATURE_OFF = 128


class RippleNsx(object):
    def __new__(cls, *args, **kwargs):
        if not hasattr(cls, "instance"):
            cls.instance = super(RippleNsx, cls).__new__(cls)
        return cls.instance

    def __init__(self, c, filtering, clustering, power_spectrum, signal_viewer) -> None:
        self.c = c
        self.filtering = filtering
        self.clustering = clustering
        self.power_spectrum = power_spectrum
        self.signal_viewer = signal_viewer
        self.b_nsx_read = False
        self.do_sorting = False
        self.legacy = False # Use ranking table generated by matlab codes & do no sorting
        self.bundles = {}
        self.micro_ch_labels = []
        self.electrode_labels = []
        self.entities = []
        self.selected_entities = []
        self.entities_visualized = {}
        self.channel = "micros"
        self.filename = ""
        self.length = 3  # in seconds
        self.current_entity = 0
        self.current_segment = 0
        self.current_analog = 0
        self.seek_time = 0 # in seconds
        self.current_event = 0
        self.max_segment = 0
        self.max_analog = 0
        self.study_info = {}
        self.photo_entity = None
        self.rec_start_time = None
        self.rec_length = None
        self.nf3_info_file = os.path.join(os.path.dirname(__file__), "nf3_info.csv")

    def get_rec_start_time(self, filename):
        """
        Get the recording start time from the filename
        because pyns does not reliably get the correct time.
        """
        # Get recording start time
        with open(filename, "rb") as fid:
            fid.seek(294, os.SEEK_SET)
            Date = np.fromfile(fid, dtype=np.uint16, count=8)

        time_year = Date[0]
        time_month = Date[1]
        time_day = Date[3]
        time_hour = Date[4]
        time_min = Date[5]
        time_sec = Date[6]
        time_millisec = Date[7]

        # Ripple records in UTC
        rec_start_time = datetime.datetime(
            time_year,
            time_month,
            time_day,
            time_hour,
            time_min,
            time_sec,
            time_millisec * 1000,
            datetime.timezone.utc,
        )

        # Convert rec_start_time from UTC to local time
        rec_start_time = rec_start_time.astimezone()

        return rec_start_time
    
    def update_channel_selection(self, channel_dict):
        """
        Update channel selection
        """
        channels = []
        for port, bundles in channel_dict.items():
            if bundles[0] == Qt.Checked or bundles[0] == Qt.PartiallyChecked:
                for bundle, electrodes in bundles[1].items():
                    if electrodes[0] == Qt.Checked or electrodes[0] == Qt.PartiallyChecked:
                        for label, electrode in electrodes[1].items():
                            if electrode[0] == Qt.Checked:
                                channels.append(label)

        self.selected_entities = []
        for i, entity in enumerate(self.entities):
            if entity.electrode_label in channels:
                self.selected_entities.append(entity)

        if len(self.selected_entities):
            self.draw_nsx_channels(channels=self.selected_entities)

    def read_nsx_file(
        self,
        filename,
        analog_only=False,
        segment_only=False,
        event_only=False,
        skip=0,
        max_segment=100,
        max_analog=90000,
    ):
        """
        Reads a Ripple NSx file and stores the entities in a list.

        Args:
            filename: path to the NSx file
            analog_only: if True, only analog entities will be stored
            segment_only: if True, only segment entities will be stored
            event_only: if True, only event entities will be stored
            skip: number of entities to skip
            max_segment: maximum number of segments to read
            max_analog: maximum number of analog entities to read
        """
        self.current_entity = skip
        self.filename = filename

        self.rec_start_time = self.get_rec_start_time(filename)
        self.c.log.emit(
            f'{os.path.basename(filename)} ({self.rec_start_time.strftime("%B %d, %Y %I:%M %p")})'
        )
        
        # if filename.endswith(".ns5"):
        #     self.ns_file = NSFile(filename, proc_single=False)
        # else:
        #     self.ns_file = NSFile(filename, proc_single=True)  
        self.ns_file = NSFile(filename, proc_single=False)
        if self.ns_file == None:
            print("Invalid file")
            return
        rec_length = self.ns_file.get_file_info().time_span # in seconds
        self.rec_end_time = self.rec_start_time + datetime.timedelta(seconds=rec_length)

        if analog_only:
            wanted_entities = [e for e in self.ns_file.get_entities(EntityType.analog)]
        elif segment_only:
            wanted_entities = [e for e in self.ns_file.get_entities(EntityType.segment)]
        elif event_only:
            wanted_entities = list(self.ns_file.get_entities(EntityType.event))
        else:
            wanted_entities = [e for e in self.ns_file.get_entities()]

        self.entities = wanted_entities
        # self.entities = [e for e in wanted_entities if e.parser.file_type=='NEURALCD' and (e.electrode_label.find('mRFUS') != -1 or e.electrode_label.find('Photo') != -1)]
        # self.entities = self.entities[6:]
        micro_ch_count = 0
        b_daq_entity_set = False
        for i, entity in enumerate(self.entities):
            if (
                entity.entity_type == EntityType.event
                and entity.electrode_label.lower().find("parallel_dig") != -1
                and b_daq_entity_set == False
            ):
                self.daq_entity = entity
                b_daq_entity_set = True

            if entity.entity_type == EntityType.analog:
                lbl = entity.electrode_label + "_" + str(entity.electrode_id)
            else:
                lbl = entity.label + "_" + str(entity.electrode_id)
            if entity.parser.file_type == "NEURALCD":
                micro_ch_count += 1
                self.micro_ch_labels.append(lbl)
            self.electrode_labels.append(lbl)
            # micro bundles
            if lbl[0].islower() and lbl.startswith("m") and lbl.find("ref") == -1:
                bundle = entity.electrode_label.split(" ")[0][:-2]
                # Check if bundle is already in the dictionary
                if bundle in self.bundles:
                    self.bundles[bundle].append(lbl)
                else:
                    self.bundles[bundle] = [lbl]

            # macro bundles
            if lbl.find("hi-res") != -1:
                bundle = entity.electrode_label.split(" ")[0][:-2]
                if bundle in self.bundles:
                    self.bundles[bundle].append(lbl)
                else:
                    self.bundles[bundle] = [lbl]

            if lbl.lower().find("photo") != -1:
                self.photo_entity = entity

            if lbl.lower().find("micl") != -1:
                self.micL_idx = micro_ch_count - 1

            if lbl.lower().find("micr") != -1:
                self.micR_idx = micro_ch_count - 1

        print(f"Analog channels: {micro_ch_count}")
        self.max_segment = max_segment
        self.max_analog = (
            wanted_entities[0].item_count if max_analog == 0 else max_analog
        )

        self.current_segment = 0
        self.current_analog = 0
        self.seek_time = 0

        ##self.load_study_info(study_folder=os.path.dirname(filename))
        self.process_ripple_nsx_file_threaded()
        # self.process_ripple_nsx_file()

        self.b_nsx_read = True
        self.c.nsx_read.emit(True)

    def process_ripple_nsx_file_threaded(self):
        if hasattr(self, "process_ripple_nsx_file_thread"):
            self.process_ripple_nsx_file_thread.join()

        self.process_ripple_nsx_file_thread = threading.Thread(
            target=self.process_ripple_nsx_file, args=())
        self.process_ripple_nsx_file_thread.daemon = True
        self.process_ripple_nsx_file_thread.start()

    def load_macros(self):
        
        macros_load_start_time = time.time()

        self.macros = [
            e
            for e in self.ns_file.get_entities(EntityType.analog)
            if e.parser.file_type == "NEUCDFLT"
        ]
        if len(self.macros) == 0:
            self.c.log.emit("No macro channels found.")            
        else:
            self.c.progress.emit(1, f'Loading {len(self.macros)} macro channels..')
            self.macros_raw_data = self.macros[0].get_analog_data_full(
                    start_index=0, index_count=self.macros[0].item_count, use_scale=False
                )
            
            self.c.log.emit(f"Loading {len(self.macros)} macro channels took {time.time() - macros_load_start_time:.2f} seconds.")
            self.c.progress.emit(100, f"Loading {len(self.macros)} macro channels took {time.time() - macros_load_start_time:.2f} seconds.")

    def load_micros(self):
        micros_load_start_time = time.time()

        self.micros = [
            e
            for e in self.ns_file.get_entities(EntityType.analog)
            if e.parser.file_type == "NEURALCD"
        ]
        
        if len(self.micros) == 0:
            return
        self.micro_ch_idxs = []
        idx = 0
        for micro in self.micros:
            lbl = micro.electrode_label + "_" + str(micro.electrode_id)
            if lbl in self.micro_ch_labels:
                self.micro_ch_idxs.append(idx)
            idx += 1
        self.c.progress.emit(1, f"Loading {len(self.micros)} micro channels..")
        self.micros_raw_data = self.micros[0].get_analog_data_full(
                start_index=0, index_count=self.micros[0].item_count, use_scale=False
        )

        entity = self.micros[0]
        item_count = entity.item_count
        ch_rec_mins, ch_rec_secs = divmod(item_count / entity.sample_freq, 60)
        self.rec_length = item_count / entity.sample_freq
        print(
            f"Loading {len(self.micros)} micro channels with {item_count} samples each ({ch_rec_mins:.0f} mins," +
            f" {ch_rec_secs:.2f} secs) took {time.time() - micros_load_start_time:.2f} seconds."
        )
        self.c.log.emit(
            f"Loading {len(self.micros)} micro channels with {item_count} samples each ({ch_rec_mins:.0f} mins," +
            f" {ch_rec_secs:.2f} secs) took {time.time() - micros_load_start_time:.2f} seconds."
        )
        self.c.progress.emit(100, f"Loading {len(self.micros)} micro channels took {time.time() - micros_load_start_time:.2f} seconds.")

    def process_ripple_nsx_file(self):
        self.load_macros()
        self.load_micros()
        # Skip rest if file is gaps
        # if self.filename.lower().find("gaps") != -1:
        #     self.c.log.emit("File is gaps. Skipping clustering.")
        #     self.c.progress.emit(100, "File is gaps. Skipping clustering.")
        #     return
        # elif not self.filename.endswith(".ns5"):
        #     self.c.log.emit("File is not ns5. Skipping clustering.")
        #     self.c.progress.emit(100, "File is not ns5. Skipping clustering.")
        #     return
        if not hasattr(self,'micros') or self.legacy:
            if self.legacy:
                self.c.nsx_processed.emit(True)
            return
        entity = self.micros[0]
        item_count = entity.item_count

        # Get available RAM
        available = psutil.virtual_memory().available
        available_gb = available / 1024**3
        usable_memory_bytes = int(np.floor(available * 0.80))
        usable_memory_gb = usable_memory_bytes / 1024**3
        self.c.log.emit(
            f"Available RAM: {available_gb:.2f} GB. Usable(80%): {usable_memory_gb:.2f} GB"
        )

        file_size = entity.parser.size
        file_size_gb = file_size / 1024**3
        self.c.log.emit(f"File size: {file_size_gb:.2f} GB")

        # usable_memory_gb = 2
        # usable_memory_bytes = 1024**3 * usable_memory_gb # 2 GB (for testing)

        if file_size_gb > usable_memory_gb:
            # Calculate item_count to read from a channel based on available memory
            item_count_new = int(
                usable_memory_bytes
                / (entity.parser.bytes_per_point * entity.parser.channel_count)
            )
            num_chunks = int(np.ceil(item_count / item_count_new))
            chunk_gb = (
                item_count_new
                * entity.parser.bytes_per_point
                * entity.parser.channel_count
                / 1024**3
            )
            self.c.log.emit(
                f"File size is greater than available RAM. Will read in {num_chunks} chunks of {chunk_gb:.2f} GB each."
            )
            print(f"File size is greater than available RAM. Will read in {num_chunks} chunks of {chunk_gb:.2f} GB each.")
            ch_rec_mins, ch_rec_secs = divmod(item_count_new / entity.sample_freq, 60)
            self.c.log.emit(
                f"{item_count_new} samples/channel ({ch_rec_mins:.2f} mins, {ch_rec_secs:.2f} secs) in each chunk."
            )
            print(f"{item_count_new} samples/channel ({ch_rec_mins:.2f} mins, {ch_rec_secs:.2f} secs) in each chunk.")
        else:
            item_count_new = item_count
            num_chunks = 1

        print("Spike sorting...")
        self.c.log.emit("Spike sorting...")
        self.c.progress.emit(1, None)
        start_time = time.time()

        self.clustering.clear_clus_info_dict(ch_lbls=self.micro_ch_labels)
        chunk_ctr = 0
        for i in range(0, item_count, item_count_new):
            index_count = min(item_count - i, item_count_new)
            raw_data = entity.get_analog_data_full(
                start_index=i, index_count=index_count, use_scale=False
            )
            raw_data = self.remove_packet_loss_data(raw_data)
            raw_data = raw_data.astype(np.float32)

            raw_data *= entity.get_analog_info().resolution # Convert to uV

            hrs, mins, secs, ms = get_elapsed_time(start_time=start_time)
            ch_rec_mins, ch_rec_secs = divmod(index_count / entity.sample_freq, 60)
            print(
                f"Loading {len(self.micros)} channels with {index_count} samples each ({ch_rec_mins:.0f} mins, {ch_rec_secs:.2f} secs) took {hrs:.0f} hours, {mins:.0f} minutes, {secs:.0f} seconds, {ms:.0f} ms."
            )
            self.c.log.emit(
                f"Loading {len(self.micros)} channels with {index_count} samples each ({ch_rec_mins:.0f} mins, {ch_rec_secs:.2f} secs) took {hrs:.0f} hours, {mins:.0f} minutes, {secs:.0f} seconds, {ms:.0f} ms."
            )
            if self.do_sorting:
                # self.clustering.process_bundle_raw_data(self.filename, raw_data, self.bundles, self.micro_ch_labels)
                self.clustering.process_raw_data(self.filename, raw_data[self.micro_ch_idxs], self.micro_ch_labels)
            else:
                self.c.log.emit("Clustering skipped. Loading clustering info from file...")
                # Load clustering info from file
                bOK = self.clustering.load_clus_info_dict_from_file(self.filename)
                if not bOK:
                    # Show pop up message box
                    self.c.log.emit("Could not load clustering info from file, starting clustering...")
                    self.clustering.process_bundle_raw_data(self.filename, raw_data, self.bundles, self.micro_ch_labels)

            if self.filename.lower().find("recall") != -1:
                micL_audio_data = raw_data[self.micL_idx]
                del raw_data
                self.c.log.emit(
                    f"Transcribing {self.micro_ch_labels[self.micL_idx]}..."
                )
                self.transcribe_audio_threaded(
                    audio_data=micL_audio_data,
                    mic_ch_lbl=self.micro_ch_labels[self.micL_idx],
                )
            else:
                # free up memory
                del raw_data
            chunk_ctr += 1
            hrs, mins, secs, ms = get_elapsed_time(start_time=start_time)
            progress_percentage = int(i / item_count * 100)
            # Remaining time = elapsed time / completed tasks * remaining tasks
            remaining_time = (
                (hrs * 3600 + mins * 60 + secs) / chunk_ctr * (num_chunks - chunk_ctr)
            )
            hrs, mins, secs, ms = get_time_hrs_mins_secs_ms(seconds=remaining_time)
            # print(f'Estimated remaining time: {hrs:.0f} hours, {mins:.0f} minutes, {secs:.0f} seconds, {ms:.0f} ms.')
            self.c.progress.emit(
                int(progress_percentage),
                f"Estimated remaining time: {hrs:.0f} hours, {mins:.0f} minutes, {secs:.0f} seconds",
            )
        self.c.nsx_processed.emit(True)
        hrs, mins, secs, ms = get_elapsed_time(start_time=start_time)
        ch_rec_mins, ch_rec_secs = divmod(item_count / entity.sample_freq, 60)
        print(
            f"Processing {len(self.micros)} channels with {item_count} samples each ({ch_rec_mins:.0f} mins, " +
            f"{ch_rec_secs:.2f} secs) took {hrs:.0f} hours, {mins:.0f} minutes, {secs:.0f} seconds, {ms:.0f} ms."
        )
        self.c.log.emit(
            f"Processing {len(self.micros)} channels with {item_count} samples each ({ch_rec_mins:.0f} mins, " +
            f"{ch_rec_secs:.2f} secs) took {hrs:.0f} hours, {mins:.0f} minutes, {secs:.0f} seconds, {ms:.0f} ms."
        )
        self.c.progress.emit(
            100,
            f"Processing {len(self.micros)} channels with {item_count} samples each ({ch_rec_mins:.0f} mins, " + 
            f"{ch_rec_secs:.2f} secs) took {hrs:.0f} hours, {mins:.0f} minutes, {secs:.0f} seconds, {ms:.0f} ms."
        )

    def remove_packet_loss_data(self, data):
        pak_lost = data == np.iinfo(np.int16).min
        data[pak_lost] = 0

        return data
    
    def transcribe_audio_threaded(self, audio_data, mic_ch_lbl):
        self.recall_transcription = {}
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(
                transcribe_audio,
                dir_save=os.path.dirname(self.filename),
                audio_data=audio_data,
                mic=mic_ch_lbl,
                c=self.c,
            )
            results = future.result()
            self.recall_transcription[mic_ch_lbl] = results
            texts = [result["text"] for result in results]
            self.c.log.emit(f"{mic_ch_lbl}: {texts}")

    def update_max_to_read(self, fs=30000):
        """
        Max data to be read calculated by multiplying self.length (in seconds)
        by the sampling rate
        """
        if hasattr(self, "length"):
            self.max_analog = int(
                self.length * fs
            )  # maximum number of analog entities to read

    def channel_waveform_clicked(self, plt_idx):
        """
        Callback for when a channel waveform is clicked.
        """
        self.current_entity = self.electrode_labels.index(
            self.entities_visualized[plt_idx].electrode_label
            + "_"
            + str(self.entities_visualized[plt_idx].electrode_id)
        )

        self.plot_power_spectrum_nsx()

    # region Plotting channels

    def load_selected_channels(self, channels):
        """
        Load the data for the selected channels.
        """
        self.vis_raw_data = []
        for i, entity in enumerate(channels):
            if hasattr(self, 'micros_raw_data') and entity in self.micros:
                    self.vis_raw_data.append(self.micros_raw_data[self.micros.index(entity)])
            elif hasattr(self, 'macros_raw_data') and entity in self.macros:
                self.vis_raw_data.append(self.macros_raw_data[self.macros.index(entity)])

    def draw_nsx_channels(self, channels=None):
        if channels is None or len(channels) == 0:
            channels = self.selected_entities

        # Load the data for the selected channels
        self.load_selected_channels(channels=channels[: self.signal_viewer.num_chs_to_plot - 2])

        self.entities_visualized.clear()

        for i, entity in enumerate(channels[: self.signal_viewer.num_chs_to_plot - 2]):
            if self.signal_viewer.b_use_multiple_pws:
                # pw = self.signal_viewer.pw_list[i]
                # plot = self.signal_viewer.ch_curves[i]
                # self.draw_entity_pw(entity=entity, pw=pw, plot=plot)
                self.ch_idx = i
                self.draw_entity(entity=entity)
            else:
                self.ch_idx = i
                self.draw_entity(entity=entity)
            self.entities_visualized[i] = entity

        self.plot_photo_analog()
        # # For when there is only one plot widget (pw)
        # pw = self.signal_viewer.pw_list[0]
        # for i, entity in enumerate(channels[: self.signal_viewer.num_chs_to_plot - 2]):
        #     plot = self.signal_viewer.ch_curves[i]
        #     self.draw_entity(entity=entity, pw=pw, plot=plot)
        #     self.entities_visualized[i] = entity

    def change_channel(self, channel):
        """
        Changes the channel to be displayed in the plot.

        Args:
                index: index of the selected
        """
        try:
            self.b_update_plot_params = True
            if not self.b_nsx_read:
                self.channel = channel
                return

            if channel != self.channel:
                self.signal_viewer.clear_layout()
                self.channel = channel
                self.signal_viewer.show_bundle_vol(channel=self.channel)

            # Draw photo diode
            self.plot_photo_analog()

            # Draw all channels micros macros and all channels.
            if channel == "All":
                pass
                # self.simulation.draw_all_channels()
            elif channel == "micros":
                self.draw_micros()
            elif channel == "macros":
                self.draw_macros()
            elif channel in self.bundles:
                self.draw_bundles(channel)
            elif channel == "test_chs":
                self.draw_test_chs()
            else:
                for entity in self.entities:
                    if -1 != self.channel.find(entity.electrode_label):
                        self.draw_nsx_channels(channels=[entity])
                        break

            # self.plot_photo_analog()
            # self.plot_power_spectrum_nsx()
            # self.sort_spikes()
            
        except:
            print(traceback.format_exc())

    def draw_event_entity(self, entity, pw=None, curve=None):
        """
        Handles drawing digital events.
        LINES_ONOFF = 13
        BLANK_ON = 11
        LINES_FLIP_BLANK = 103
        LINES_FLIP_PIC = 22
        TRIAL_ON = 26
        DATA_SIGNATURE_ON = 64
        DATA_SIGNATURE_OFF = 128
        """
        # entity = self.entities[self.current_entity]
        if entity.entity_type != EntityType.event:
            sys.stderr.write("must specify event entity\n")
            return False
        item_count = entity.item_count
        title = "16 bit digital input events"
        if item_count == 0:
            return False

        self.curr_time = int(self.current_analog / 30000)

        timestamps = []
        events = []
        for item in range(self.current_event, item_count):
            data_rt = entity.get_event_data(item)
            timestamp = data_rt[0]
            if timestamp >= self.curr_time and timestamp < self.curr_time + self.length:
                timestamps.append(data_rt[0])
                for iData in range(0, 6):
                    if data_rt[1][iData] != 0:
                        events.append(data_rt[1][iData])
                        break
            elif timestamp >= self.curr_time + self.length:
                self.current_event = item
                break

        self.signal_viewer.draw_events(events=events, timestamps=timestamps)

        # pw.setLabel('bottom', 'Time', units='s')
        # pw.setXRange(0, timestamps[-1])
        # pw.setYRange(values.min(), values.max())
        # pw.setTitle(title, color='k', size='10pt')

        # curve.setData(x=timestamps, y=values)

        return True

    def draw_entity(self, entity=None):
        """This function is called each time an entity is called to draw.
        It looks at the entity and calls the appropriate function.
        """
        if entity is None:
            entity = self.entities[self.current_entity]
        else:
            self.current_entity = self.entities.index(entity)

        if entity.entity_type == EntityType.segment:
            return self.draw_segment_entity(entity=entity)
        elif entity.entity_type == EntityType.analog:
            self.update_max_to_read(fs=entity.sample_freq)
            return self.draw_analog_entity(entity=entity)
        elif entity.entity_type == EntityType.event:
            return self.draw_event_entity(entity=entity)
        # return false if we don't have an analog or segment entity
        return False
    
    def draw_entity_pw(self, entity=None, pw=None, plot=None):
        """This function is called each time an entity is called to draw.
        It looks at the entity and calls the appropriate function.
        """
        if entity is None:
            entity = self.entities[self.current_entity]
        else:
            self.current_entity = self.entities.index(entity)

        if entity.entity_type == EntityType.segment:
            return self.draw_segment_entity(entity=entity, pw=pw, curve=plot)
        elif entity.entity_type == EntityType.analog:
            self.update_max_to_read(fs=entity.sample_freq)
            return self.draw_analog_entity_pw(entity=entity, pw=pw, plot=plot)
        elif entity.entity_type == EntityType.event:
            return self.draw_event_entity(entity=entity, pw=pw, curve=plot)
        # return false if we don't have an analog or segment entity
        return False

    def draw_segment_entity(self, entity, pw=None, curve=None):
        """A utility function to overlay all the segment waveforms for a
        a specified segment entity.
        """
        if pw is None:
            pw = self.graph
        # entity = self.entities[self.current_entity]
        if entity.entity_type != EntityType.segment:
            sys.stderr.write("must specify segment entity\n")
            return False
        item_count = min(entity.item_count - self.current_segment, self.max_segment)
        title = "Overlay of {0:d} segment waveforms for {1:s}".format(
            item_count, entity.label
        )
        if item_count <= 0:
            return False

        # get the time resolution though it should always be 1/30kHz
        segment_info = entity.get_segment_info()

        for item in range(self.current_segment, self.current_segment + item_count):
            # get the segment info for the time resolution,
            # though it should always be 30000
            segment_info = entity.get_segment_info()
            (timestamp, waveform, a) = entity.get_segment_data(item)
            # create physical time dimensions in milliseconds
            time = np.arange(0, len(waveform), dtype=np.double)
            time *= 1.0 / segment_info.sample_rate
            time *= 1000.0
            curve.setData(x=time, y=waveform)

        return True

    def draw_all_channels(self):
        self.draw_nsx_channels(channels=self.entities)

    def draw_micros(self):
        micros = []
        for i, entity in enumerate(self.entities):
            if (
                entity.entity_type == EntityType.analog
                and entity.electrode_label[0].islower()
                and entity.electrode_label.startswith("m")
                and entity.electrode_label.find("raw") != -1
            ):
                micros.append(entity)

        self.draw_nsx_channels(channels=micros)

    def draw_macros(self):
        macros = []
        for i, entity in enumerate(self.entities):
            if (
                entity.entity_type == EntityType.analog
                and entity.electrode_label.find("hi-res") != -1
            ):
                macros.append(entity)

        self.draw_nsx_channels(channels=macros)

    def draw_test_chs(self):
        test_chs_lbls = ["LK01", "LP01"]
        test_chs = []
        for ch_lbl in test_chs_lbls:
            for i, entity in enumerate(self.entities):
                if (
                    entity.entity_type == EntityType.analog
                    and entity.electrode_label.find(ch_lbl) != -1
                ):
                    test_chs.append(entity)

        self.draw_nsx_channels(channels=test_chs)

    def draw_bundles(self, bundle):
        entities = []
        for i, entity in enumerate(self.electrode_labels):
            if entity.find(bundle) != -1:
                entities.append(self.entities[i])

        self.draw_nsx_channels(channels=entities)

    def draw_analog_entity(self, entity):
        """A utility function to draw any analog entity"""

        if entity.entity_type != EntityType.analog:
            sys.stderr.write("must specify analog entity\n")
            return False
        self.current_analog = int(self.seek_time * entity.sample_freq)
        
        item_count = min(self.max_analog, entity.item_count - self.current_analog)
        if item_count <= 0:
            return False

        # The analog info will be useful to get time axis
        # resolution (i.e., ns2 or ns5 files)
        analog_info = entity.get_analog_info()
        entity_info = entity.get_entity_info()

        self.waveform = self.vis_raw_data[self.ch_idx][self.current_analog:self.current_analog + item_count]
        # self.waveform = entity.get_analog_data(start_index=self.current_analog, index_count=item_count, use_scale=True)
        # self.waveform = self.waveform.astype(np.float32)
        # Divide by sample rate to get time in seconds
        # self.time = np.arange(
        #     self.current_analog, self.current_analog + len(self.waveform)
        # )
        # if analog_info.sample_rate != 30000:
        #     self.waveform = np.where(self.waveform == np.finfo(np.float32).max, 0, self.waveform)
        #     dc = (self.waveform.max() + self.waveform.min()) / 2
        #     scale = np.abs(self.waveform - dc).max() / 32767 # 16 bit (int16)
        #     self.waveform = ((self.waveform - dc) / scale).round() 

        self.time = np.arange(0,len(self.waveform))
        self.time = self.time.astype(np.double)
        self.time *= 1.0 / analog_info.sample_rate
        # waveform *= analog_info.resolution

        if self.signal_viewer.raw:
            curve = self.signal_viewer.ch_curves[self.ch_idx]
            curve.setData(x=self.time, y=self.waveform)
            self.signal_viewer.pw_list[self.ch_idx].setXRange(self.time[0], self.time[-1])
            self.signal_viewer.pw_list[self.ch_idx].setYRange(-self.signal_viewer.raw_y, self.signal_viewer.raw_y)
            self.signal_viewer.pw_list[self.ch_idx].setLabel("left", entity_info.label.split(" ")[0])

        self.waveform_length = len(self.waveform)

        # display filtered data
        self.filtering.fs = analog_info.sample_rate
        if analog_info.sample_rate < 30000:
            self.filtering.lowcut = 1
            self.filtering.highcut = 120
        else:
            self.filtering.lowcut = 300
            self.filtering.highcut = 3000
        self.filtered_data = self.filtering.custom_bp_filter(data=self.waveform, 
                                                             channel=entity.electrode_label + "_" + str(entity.electrode_id),
                                                             fs=analog_info.sample_rate)
        if self.signal_viewer.filt and self.filtered_data is not None:
            curve = self.signal_viewer.ch_filt_curves[self.ch_idx]
            
            curve.setData(x=self.time, y=self.filtered_data)

        if self.filtered_data is None:
            return False

        if analog_info.units == "uV":
            spikes, thr = detect_spikes(data=self.filtered_data)
        else:
            spikes, thr = detect_spikes(
                data=self.filtered_data, distance=10000, det_neg=False
            )
            self.photo_spikes = spikes
            self.signal_viewer.plot_pics(time_arr=self.time, spikes=spikes)

        # Mark spikes on filtered curve
        spike_plot = self.signal_viewer.ch_spikes[self.ch_idx]
        spike_plot.setData(x=self.time[spikes], y=self.waveform[spikes])

        filt_spikes = self.signal_viewer.ch_filt_spikes[self.ch_idx]
        filt_spikes.setData(x=self.time[spikes], y=self.filtered_data[spikes])

        # Add 500ms region around stimulus onset
        region = self.signal_viewer.region_list[self.ch_idx]
        if self.signal_viewer.region:
            if hasattr(self, "photo_spikes") and len(self.photo_spikes) > 0:
                region.setRegion(
                    [
                        self.time[self.photo_spikes[0]] - 0.25,
                        self.time[self.photo_spikes[0]] + 0.25,
                    ]
                )  # 500ms
            else:
                # 500ms at the center
                region.setRegion(
                    [
                        self.time[len(self.time) // 2] - 0.25,
                        self.time[len(self.time) // 2] + 0.25,
                    ]
                )  # 500ms
            # TODO: Add region to the plot widget
        else:
            pass
            # TODO: Remove region from the plot widget

        if (
            hasattr(self, "recall_transcription")
            and entity.electrode_label.lower().find("micl") != -1
        ):
            self.signal_viewer.plot_audio_transcription(
                transcription=self.recall_transcription[
                    entity.electrode_label + "_" + str(entity.electrode_id)
                ],
            )

        return True
    
    def draw_analog_entity_pw(self, entity, pw=None, plot=None):
        """A utility function to draw any analog entity"""

        if entity.entity_type != EntityType.analog:
            sys.stderr.write("must specify analog entity\n")
            return False
        self.current_analog = int(self.seek_time * entity.sample_freq)
        item_count = min(self.max_analog, entity.item_count - self.current_analog)
        if item_count <= 0:
            return False

        # The analog info will be useful to get time axis
        # resolution (i.e., ns2 or ns5 files)
        analog_info = entity.get_analog_info()
        entity_info = entity.get_entity_info()

        self.waveform = entity.get_analog_data(
            start_index=self.current_analog, index_count=item_count, use_scale=True
        )
        self.waveform = self.waveform.astype(np.float32)
        # Divide by sample rate to get time in seconds
        self.time = np.arange(
            self.current_analog, self.current_analog + len(self.waveform)
        )
        self.time = self.time.astype(np.double)
        self.time *= 1.0 / analog_info.sample_rate
        # waveform *= analog_info.resolution

        if pw is None:
            pw = self.signal_viewer.pw_list[0]
        if plot is None:
            plot = self.signal_viewer.ch_curves[0]

        pw.setLabel("left", entity_info.label.split(" ")[0], units="uV")
        # pw.setLabel('bottom', 'Time', units='s')
        pw.setXRange(self.time[0], self.time[-1])
        # pw.setYRange(-self.range, self.range)
        # pw.hideAxis('bottom')
        idx = self.signal_viewer.ch_curves.index(plot)
        if self.signal_viewer.raw:
            pw.addItem(plot)
            self.signal_viewer.glw_chs.addItem(pw, row=idx, col=0)
        else:
            self.signal_viewer.glw_chs.removeItem(pw)

        filtered_curve = self.signal_viewer.ch_filt_curves[idx]
        if self.signal_viewer.filt:
            self.signal_viewer.filtered_vb_list[idx].setYRange(
                -self.signal_viewer.filt_y, self.signal_viewer.filt_y - 20
            )
            self.signal_viewer.filtered_vb_list[idx].addItem(filtered_curve)
        else:
            self.signal_viewer.filtered_vb_list[idx].removeItem(filtered_curve)

        plot.setData(x=self.time, y=self.waveform)
        self.waveform_length = len(self.waveform)

        # display filtered data
        self.filtered_data = self.filtering.custom_bp_filter(data=self.waveform, 
                                                             channel=entity.electrode_label + "_" + str(entity.electrode_id))
        filtered_curve.setData(x=self.time, y=self.filtered_data)

        if analog_info.units == "uV":
            pw.setYRange(-self.signal_viewer.raw_y, self.signal_viewer.raw_y)
            spikes, thr = detect_spikes(data=self.filtered_data)
        else:
            # photo diode. Set y range to 0-5V
            pw.setYRange(-5000, 5000)
            spikes, thr = detect_spikes(
                data=self.filtered_data, distance=10000, det_neg=False
            )
            self.photo_spikes = spikes
            self.signal_viewer.plot_pics(time_arr=self.time, spikes=spikes)

        # Mark spikes on filtered curve
        spike_plot = self.signal_viewer.ch_spikes[idx]
        spike_plot.setData(x=self.time[spikes], y=self.waveform[spikes])

        filt_spikes = self.signal_viewer.ch_filt_spikes[idx]
        filt_spikes.setData(x=self.time[spikes], y=self.filtered_data[spikes])
        if self.signal_viewer.spikes:
            pw.addItem(spike_plot)
            self.signal_viewer.filtered_vb_list[idx].addItem(filt_spikes)
        else:
            pw.removeItem(spike_plot)
            self.signal_viewer.filtered_vb_list[idx].removeItem(filt_spikes)

        # Add 500ms region around stimulus onset
        region = self.signal_viewer.region_list[idx]
        if self.signal_viewer.region:
            if hasattr(self, "photo_spikes") and len(self.photo_spikes) > 0:
                region.setRegion(
                    [
                        self.time[self.photo_spikes[0]] - 0.25,
                        self.time[self.photo_spikes[0]] + 0.25,
                    ]
                )  # 500ms
            else:
                # 500ms at the center
                region.setRegion(
                    [
                        self.time[len(self.time) // 2] - 0.25,
                        self.time[len(self.time) // 2] + 0.25,
                    ]
                )  # 500ms
            pw.addItem(region)
        else:
            pw.removeItem(region)

        if (
            hasattr(self, "recall_transcription")
            and entity.electrode_label.lower().find("micl") != -1
        ):
            self.signal_viewer.plot_audio_transcription(
                plot=pw,
                transcription=self.recall_transcription[
                    entity.electrode_label + "_" + str(entity.electrode_id)
                ],
            )

        return True

    def plot_photo_analog(self):
        if not self.signal_viewer.ph_diode:
            return
        if hasattr(self, "daq_entity"):
            # self.draw_entity_pw(
            #     entity=self.daq_entity,
            #     pw=self.signal_viewer.pw_daq,
            #     plot=self.signal_viewer.ch_curves[-2],
            # )
            self.ch_idx = -2
            self.draw_entity(entity=self.daq_entity)
        if hasattr(self, "photo_entity") and self.photo_entity is not None:
            # self.draw_entity_pw(
            #     entity=self.photo_entity,
            #     pw=self.signal_viewer.pw_photo,
            #     plot=self.signal_viewer.ch_curves[-1],
            # )
            self.ch_idx = -1
            self.draw_entity(entity=self.photo_entity)
        # Get the x-axis
        x_axis = self.signal_viewer.pw_photo.getAxis('bottom')

        # Get the existing ticks
        tick_vals = x_axis.tickValues(0, self.length, self.length)[0][1]

        curr_time = self.rec_start_time.replace(tzinfo=None) + timedelta(seconds=self.seek_time)
        curr_time_str = curr_time.strftime('%H:%M:%S') # Label for the first tick

        ticks = []
        for tic_val in tick_vals:
            if tic_val <=0:
                curr_time = self.rec_start_time.replace(tzinfo=None) + timedelta(seconds=self.seek_time)
                ticks.append((tic_val, curr_time.strftime('%H:%M:%S')))
            else:
                tick_time = curr_time + timedelta(seconds=tic_val)
                ticks.append((tic_val, tick_time.strftime('%H:%M:%S')))

        ticks = [ticks]

        # Set the custom labels
        x_axis.setTicks(ticks)

        # for pw in self.pw_list[:-1]:
        #     # link the x axis of the photo diode plot with the other plots
        #     pw.setXLink(self.pw_photo)

    # endregion Plotting channels

    # region Power spectrum

    def plot_power_spectrum_nsx(self):
        """
        Plots the power spectrum of a selected channel.
        There are two plots: one with most of the frequency range(10kHz) and one with 0 to 300 Hz.
        """
        fs = self.entities[self.current_entity].sample_freq
        fft_length = 2 ** np.ceil(np.log2(fs * 2)) / fs
        nfft = int(fft_length * fs)

        ch_label = self.entities[self.current_entity].electrode_label.split(" ")[0]
        data = self.entities[self.current_entity].get_analog_data(0, 5 * nfft)
        self.filtering.fs = fs
        filtered_data = self.filtering.custom_bp_filter(data=data)

        # Spike clustering, sorting
        # other_params = ss.get_default_sorter_params('tridesclous')
        # other_params['detect_threshold'] = 6
        # sorting_TDC = ss.run_sorter(sorter_name='tridesclous', recording=filtered_data,
        #                             output_folder='tridesclous_output', verbose=True, **other_params)
        # print(sorting_TDC)

        self.power_spectrum.plot_power_spectrum_nsx(
            ch_label=ch_label, data=data, filtered_data=filtered_data, fs=fs
        )

    # endregion Power spectrum

    # region Playback functions (previous, next, etc.)

    def navigate(self, direction):
        if direction == "previous":
            self.previous()
        elif direction == "next":
            self.next()
        elif direction == "forward":
            self.forward()
        elif direction == "back":
            self.back()

    def previous(self):
        if self.current_entity != 0:
            self.current_entity -= 1
            # if we fail to draw an entity (basically if the
            # entity has zero items keep iterating back
            if not self.draw_entity():
                self.previous()

    def next(self):
        self.current_analog = 0
        self.current_segment = 0

        if self.current_entity < len(self.entities) - 1:
            self.current_entity += 1
            # if we fail to draw an entity (basically if the
            # entity has zero items keep iterating forward)
            if not self.draw_entity():
                self.next()
        else:
            sys.exit(0)

    def forward(self):
        self.seek_time += self.length
        self.draw_nsx_channels(channels=self.selected_entities)

    def back(self):
        self.seek_time -= self.length
        self.draw_nsx_channels(channels=self.selected_entities)

    def go_to_time(self, event_time):
        """
        Go to a specific time in the recording, given time of event in local time
        """
        # Locals
        bOK = True
        # Subtract event time from recording start time to get amount to seek
        if self.rec_start_time is None or \
        (event_time.replace(tzinfo=None) < self.rec_start_time.replace(tzinfo=None) or \
         event_time.replace(tzinfo=None) > self.rec_end_time.replace(tzinfo=None)):
            bOK = self.find_recording(event_time)

        if bOK:
            seek_time = event_time.replace(tzinfo=None) - self.rec_start_time.replace(tzinfo=None)
            self.seek_time = seek_time.total_seconds()
            self.draw_nsx_channels(channels=self.selected_entities)

    def find_recording(self, date_time):
        """
        Find the recording which matches the datetime
        """
        bOK = False
        if not hasattr(self, "nf3_info_df"):
            self.nf3_info_df = pd.read_csv(self.nf3_info_file)

            # Check if date_time falls between 'recording_start_time' and 'recording_end_time' column values in the nf3_info_df
            self.nf3_info_df["recording_start_time"] = pd.to_datetime(self.nf3_info_df["recording_start_time"], format='mixed')
            self.nf3_info_df["recording_end_time"] = pd.to_datetime(self.nf3_info_df["recording_end_time"], format='mixed')

        for row in self.nf3_info_df.itertuples():
            try:
                if date_time.replace(tzinfo=None) >= row.recording_start_time.replace(tzinfo=None) and \
                   date_time.replace(tzinfo=None) <= row.recording_end_time.replace(tzinfo=None):
                    self.read_nsx_file(row.nf3_file)
                    bOK = True
                    break
            except:
                print(f'Error: file:{os.path.basename(row.nf3_file)} recording_start_time: {row.recording_start_time}, recording_end_time: {row.recording_end_time}')


        return bOK

    # endregion Playback functions (previous, next, etc.)
